{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Experiment on image classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Basic Image classification example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "At the first step we need to import the necessary libraries and packages, and also configure a path to train and validation datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "\n",
    "from torchvision.transforms import ToTensor, Resize, Compose\n",
    "\n",
    "from fedot_ind.api.main import FedotIndustrial\n",
    "\n",
    "\n",
    "DATASETS_PATH = os.path.abspath('../data/cv/datasets')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T13:54:41.183740Z",
     "start_time": "2023-05-31T13:54:33.990157Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's take a look at the datasets available in the folder:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "['Agricultural', 'minerals']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(DATASETS_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T13:54:41.194327Z",
     "start_time": "2023-05-31T13:54:41.187009Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this example we will use the dataset with images of agricultural products. The dataset contains 3 classes: `cherry`, `banana` and `lemon`. The dataset is divided into train and validation parts. The train part contains 3 folders with images of each class as well as the validation part."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(['train', 'val'], ['Lemon', 'Cherry', 'banana'])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join(DATASETS_PATH, 'Agricultural')), os.listdir(os.path.join(DATASETS_PATH, 'Agricultural/train'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T13:54:41.203117Z",
     "start_time": "2023-05-31T13:54:41.194690Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As it was described in other examples, we need to instantiate the class FedotIndustrial with appropriate task type. Also, as the important parameter either the number of classes or torch model should be passed, as well as the device (`cuda` or `cpu`, depending on hardware used)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-31 15:54:41,204 - Initialising experiment setup\n",
      "2023-05-31 15:54:41,206 - Initialising solver\n"
     ]
    }
   ],
   "source": [
    "fed = FedotIndustrial(task='image_classification',\n",
    "                      num_classes=3,\n",
    "                      # Taking into account macOS specifics\n",
    "                      device='cpu' if platform.system() == 'Darwin' else 'cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T13:54:41.438674Z",
     "start_time": "2023-05-31T13:54:41.206849Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next step is model training with conventional method fit. Here we pass dataset_path, transform option and desirable number of epochs:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/61 [00:00<?, ?it/s]/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 61/61 [00:00<00:00, 92.93it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-31 15:54:42,117 - train: ResNet, using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-31 15:54:55,166 - Best f1 score: 0.17543859649122806\n",
      "2023-05-31 15:54:55,255 - Saved to /Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/fedot_ind/results_of_experiments/models/train/ResNet/train.sd.pt.\n",
      "2023-05-31 15:54:55,259 - Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 6/6 [00:28<00:00,  4.74s/it, loss=1.92]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-31 15:55:36,851 - Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 6/6 [00:29<00:00,  4.84s/it, loss=1.43]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 2/2 [00:14<00:00,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-31 15:56:20,136 - Model state dict loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "trained_model = fed.fit(dataset_path=os.path.join(DATASETS_PATH, 'Agricultural/train'),\n",
    "                        transform=Compose([ToTensor(), Resize((256, 256))]),\n",
    "                        num_epochs=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T13:56:20.156277Z",
     "start_time": "2023-05-31T13:54:41.438998Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "At this moment we can inspect the model architecture:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=3, bias=True)\n)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T13:56:20.174248Z",
     "start_time": "2023-05-31T13:56:20.162853Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To obtain predict one must use the following code:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 30/30 [00:02<00:00, 14.00it/s]\n"
     ]
    }
   ],
   "source": [
    "predict = fed.predict(data_path=os.path.join(DATASETS_PATH, 'Agricultural/val'),\n",
    "                      transform=Compose([ToTensor(), Resize((256, 256))]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T13:56:44.673023Z",
     "start_time": "2023-05-31T13:56:42.508609Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "{'/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images32.jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images24.jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images34.jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images20.jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images21.jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images23.jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/image32.jpeg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images10.jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images11.jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images28.jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images27.jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images25.jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images30.jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images20.jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images21.jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images37.jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images53.jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images42.jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images54.jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images41.jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (26).jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (30).jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (27).jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (21).jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (22).jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (23).jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (24).jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (28).jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (29).jpg': 0,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (25).jpg': 0}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T13:56:44.673691Z",
     "start_time": "2023-05-31T13:56:44.665959Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:02<00:00, 14.69it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_proba = fed.predict_proba(data_path=os.path.join(DATASETS_PATH, 'Agricultural/val'),\n",
    "                                  transform=Compose([ToTensor(), Resize((256, 256))]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T13:57:31.016891Z",
     "start_time": "2023-05-31T13:57:28.943044Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "{'/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images32.jpg': [0.3739467263221741,\n  0.2950085997581482,\n  0.33104467391967773],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images24.jpg': [0.3583826720714569,\n  0.3067706227302551,\n  0.33484676480293274],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images34.jpg': [0.36658844351768494,\n  0.3097815215587616,\n  0.3236300051212311],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images20.jpg': [0.3646151125431061,\n  0.3090839982032776,\n  0.32630085945129395],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images21.jpg': [0.37269771099090576,\n  0.30590638518333435,\n  0.3213958442211151],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images23.jpg': [0.3621959090232849,\n  0.3050382435321808,\n  0.3327659070491791],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/image32.jpeg': [0.362784206867218,\n  0.31431668996810913,\n  0.32289910316467285],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images10.jpg': [0.3702128231525421,\n  0.297269731760025,\n  0.3325174152851105],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images11.jpg': [0.36714908480644226,\n  0.3098503053188324,\n  0.32300060987472534],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images28.jpg': [0.3633870482444763,\n  0.30804914236068726,\n  0.3285638391971588],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images27.jpg': [0.35908061265945435,\n  0.3145729899406433,\n  0.32634636759757996],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images25.jpg': [0.36739829182624817,\n  0.29843008518218994,\n  0.3341716527938843],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images30.jpg': [0.3751567602157593,\n  0.3073166012763977,\n  0.31752660870552063],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images20.jpg': [0.3670947551727295,\n  0.30377432703971863,\n  0.3291308283805847],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images21.jpg': [0.3456236720085144,\n  0.3240468204021454,\n  0.3303295075893402],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images37.jpg': [0.3575959801673889,\n  0.30419281125068665,\n  0.3382112383842468],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images53.jpg': [0.3721415102481842,\n  0.306440144777298,\n  0.32141831517219543],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images42.jpg': [0.36566582322120667,\n  0.31060150265693665,\n  0.3237326443195343],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images54.jpg': [0.3452846109867096,\n  0.32720261812210083,\n  0.3275127708911896],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images41.jpg': [0.3472914397716522,\n  0.3182098865509033,\n  0.33449867367744446],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (26).jpg': [0.37232205271720886,\n  0.3015210032463074,\n  0.326156884431839],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (30).jpg': [0.36770889163017273,\n  0.30922046303749084,\n  0.32307058572769165],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (27).jpg': [0.3585386872291565,\n  0.303291380405426,\n  0.3381698727607727],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (21).jpg': [0.37255820631980896,\n  0.2979326844215393,\n  0.32950910925865173],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (22).jpg': [0.36697784066200256,\n  0.3024178147315979,\n  0.33060431480407715],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (23).jpg': [0.3723229765892029,\n  0.29967695474624634,\n  0.3280000388622284],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (24).jpg': [0.35526594519615173,\n  0.31050214171409607,\n  0.3342318832874298],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (28).jpg': [0.3635249137878418,\n  0.3086223006248474,\n  0.3278527557849884],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (29).jpg': [0.36075857281684875,\n  0.30560413002967834,\n  0.3336372971534729],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (25).jpg': [0.3604835271835327,\n  0.30916041135787964,\n  0.33035609126091003]}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T13:57:35.807083Z",
     "start_time": "2023-05-31T13:57:35.744787Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Advanced Image classification example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this example we will use the same dataset as in the previous example, but we will use the advanced features of\n",
    "FedotIndustrial class. To conduct an advanced experiment one should instantiate FedotIndustrial class with optimization method argument and optimization parameters:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-31 15:59:33,966 - Initialising experiment setup\n",
      "2023-05-31 15:59:33,968 - Initialising solver\n"
     ]
    }
   ],
   "source": [
    "fed = FedotIndustrial(task='image_classification',\n",
    "                      num_classes=3,\n",
    "                      optimization='svd',\n",
    "                      optimization_params={'energy_thresholds': [0.9]},\n",
    "                      # Taking into account hardware specifics\n",
    "                      device='cpu' if platform.system() == 'Darwin' else 'cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T13:59:34.259457Z",
     "start_time": "2023-05-31T13:59:33.969120Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Method fit also must be provided with additional argument – finetuning_params:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:00<00:00, 76.39it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-31 16:01:09,905 - Default size: 44.75 Mb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-31 16:01:11,359 - SVD decomposed size: 50.70 Mb\n",
      "2023-05-31 16:01:11,362 - train: ResNet_SVD_channel_O-10_H-0.1, using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-31 16:01:24,968 - Best f1 score: 0.14814814814814817\n",
      "2023-05-31 16:01:25,074 - Saved to /Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/fedot_ind/results_of_experiments/models/train/ResNet_SVD_channel_O-10_H-0.1/train.sd.pt.\n",
      "2023-05-31 16:01:25,077 - Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 6/6 [00:32<00:00,  5.48s/it, loss=1.81, orthogonal_loss=0.0535, hoer_loss=1.34]  \n",
      "  0%|          | 0/2 [00:00<?, ?it/s]/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-31 16:02:11,468 - Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 6/6 [00:30<00:00,  5.08s/it, loss=1.18, orthogonal_loss=0.372, hoer_loss=1.34] \n",
      "  0%|          | 0/2 [00:00<?, ?it/s]/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-31 16:02:55,606 - Best f1 score: 0.17543859649122806\n",
      "2023-05-31 16:02:55,711 - Saved to /Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/fedot_ind/results_of_experiments/models/train/ResNet_SVD_channel_O-10_H-0.1/train.sd.pt.\n",
      "2023-05-31 16:02:55,760 - Model state dict loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-31 16:02:55,902 - Saved to /Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/fedot_ind/results_of_experiments/models/train/ResNet_SVD_channel_O-10_H-0.1/trained.model.pt.\n",
      "2023-05-31 16:02:55,947 - Model loaded.\n",
      "2023-05-31 16:02:56,151 - Saved to /Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/fedot_ind/results_of_experiments/models/train/ResNet_SVD_channel_O-10_H-0.1/e_0.9.sd.pt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 2/2 [00:14<00:00,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-31 16:03:10,466 - pruning with e=0.9, size: 41.24 Mb, f1: 0.1754\n",
      "2023-05-31 16:03:10,469 - e_0.9: ResNet_SVD_channel_O-10_H-0.1, using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-31 16:03:23,993 - Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 6/6 [00:31<00:00,  5.29s/it, loss=1.27, orthogonal_loss=0.37]  \n",
      "  0%|          | 0/2 [00:00<?, ?it/s]/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 2/2 [00:14<00:00,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-31 16:04:10,094 - Model state dict loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "fitted_model = fed.fit(dataset_path=os.path.join(DATASETS_PATH, 'Agricultural/train'),\n",
    "                       transform=Compose([ToTensor(), Resize((256, 256))]),\n",
    "                       num_epochs=2,\n",
    "                       finetuning_params={'num_epochs': 1})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T14:04:10.117757Z",
     "start_time": "2023-05-31T14:01:09.099892Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): DecomposedConv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): DecomposedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): DecomposedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): DecomposedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): DecomposedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): DecomposedConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): DecomposedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): DecomposedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): DecomposedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): DecomposedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): DecomposedConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): DecomposedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): DecomposedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): DecomposedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): DecomposedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): DecomposedConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): DecomposedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): DecomposedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): DecomposedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): DecomposedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=3, bias=True)\n)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T14:04:10.222538Z",
     "start_time": "2023-05-31T14:04:10.122946Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To obtain predict one must use the following code:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/venv39/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 30/30 [00:03<00:00,  9.00it/s]\n"
     ]
    }
   ],
   "source": [
    "predict = fed.predict(data_path=os.path.join(DATASETS_PATH, 'Agricultural/val'),\n",
    "                      transform=Compose([ToTensor(), Resize((256, 256))]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T14:04:13.477555Z",
     "start_time": "2023-05-31T14:04:10.133938Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "{'/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images32.jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images24.jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images34.jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images20.jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images21.jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images23.jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/image32.jpeg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images10.jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images11.jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images28.jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images27.jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images25.jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images30.jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images20.jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images21.jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images37.jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images53.jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images42.jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images54.jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images41.jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (26).jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (30).jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (27).jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (21).jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (22).jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (23).jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (24).jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (28).jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (29).jpg': 2,\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (25).jpg': 2}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T14:04:13.493425Z",
     "start_time": "2023-05-31T14:04:13.482995Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:03<00:00,  8.80it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_proba = fed.predict_proba(data_path=os.path.join(DATASETS_PATH, 'Agricultural/val'),\n",
    "                                  transform=Compose([ToTensor(), Resize((256, 256))]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T14:04:16.911290Z",
     "start_time": "2023-05-31T14:04:13.491389Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "{'/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images32.jpg': [0.0010848587844520807,\n  5.759836746823451e-16,\n  0.9989151954650879],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images24.jpg': [5.675259308191016e-05,\n  2.2503946165342357e-20,\n  0.9999432563781738],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images34.jpg': [0.002302838722243905,\n  2.5224039437027335e-13,\n  0.9976971745491028],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images20.jpg': [0.00023580754350405186,\n  3.0562785077895024e-18,\n  0.9997641444206238],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images21.jpg': [2.482033050910104e-05,\n  1.9059929601776675e-21,\n  0.9999752044677734],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images23.jpg': [0.00014699703024234623,\n  7.991118411284775e-19,\n  0.9998530149459839],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/image32.jpeg': [9.24052728805691e-05,\n  2.1304014704318207e-19,\n  0.9999076128005981],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images10.jpg': [0.00013001148181501776,\n  3.1268543848331393e-19,\n  0.9998699426651001],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images11.jpg': [0.03297027200460434,\n  9.036411938723177e-07,\n  0.9670288562774658],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Lemon/images28.jpg': [0.0016785444458946586,\n  3.5898996957343856e-15,\n  0.9983214735984802],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images27.jpg': [5.780468927696347e-05,\n  7.761532622813092e-20,\n  0.9999421834945679],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images25.jpg': [0.1556919366121292,\n  1.0716841643443331e-05,\n  0.8442974090576172],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images30.jpg': [6.5111686126329e-05,\n  1.0263827000324453e-19,\n  0.9999349117279053],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images20.jpg': [0.002670290879905224,\n  3.15537018443033e-14,\n  0.9973297119140625],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images21.jpg': [6.137396121630445e-05,\n  4.499148119657863e-20,\n  0.9999386072158813],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images37.jpg': [0.0004268386692274362,\n  1.8752205993273064e-17,\n  0.9995731711387634],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images53.jpg': [5.202415559324436e-05,\n  1.6872641111161993e-20,\n  0.9999480247497559],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images42.jpg': [1.2089812116755638e-05,\n  2.234035908230649e-22,\n  0.9999879598617554],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images54.jpg': [4.952431845595129e-05,\n  3.1407094662229464e-20,\n  0.9999505281448364],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/Cherry/images41.jpg': [0.0068768663331866264,\n  7.933409137961256e-12,\n  0.9931231141090393],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (26).jpg': [0.0002899031387642026,\n  2.8271757410967623e-18,\n  0.9997100234031677],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (30).jpg': [0.0005495661171153188,\n  5.933780785893634e-16,\n  0.9994503855705261],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (27).jpg': [0.006862198002636433,\n  3.957375226126825e-12,\n  0.993137776851654],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (21).jpg': [0.000948931323364377,\n  4.4405567263930727e-16,\n  0.999051034450531],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (22).jpg': [0.010462449863553047,\n  2.01385748355154e-11,\n  0.9895375967025757],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (23).jpg': [0.003152089426293969,\n  7.053014314077621e-14,\n  0.996847927570343],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (24).jpg': [0.000499173766002059,\n  2.7746969628535912e-17,\n  0.9995008707046509],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (28).jpg': [0.012609410099685192,\n  2.639942708881904e-10,\n  0.9873906373977661],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (29).jpg': [0.0005928902537561953,\n  8.012098544712718e-17,\n  0.999407172203064],\n '/Users/technocreep/Desktop/Working-Folder/fedot-industrial/Fedot.Industrial/examples/data/cv/datasets/Agricultural/val/banana/image (25).jpg': [0.00031090975971892476,\n  2.5426588646935066e-15,\n  0.9996891021728516]}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T14:04:16.923250Z",
     "start_time": "2023-05-31T14:04:16.910457Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
