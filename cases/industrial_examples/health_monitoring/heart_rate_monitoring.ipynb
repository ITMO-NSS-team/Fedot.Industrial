{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Heart Rate Monitoring During Physical Exercise Using Wrist-Type Photoplethysmographic (PPG) Signals with Fedot.Industrial"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The goal of this dataset is to estimate heart rate using PPG sensors. This dataset contains 3096, 5 dimensional time series obtained from the IEEE Signal Processing Cup 2015: Heart Rate Monitoring During Physical Exercise Using Wrist-Type Photoplethysmographic (PPG) Signals. Two-channel PPG signals, three-axis acceleration signals, and one-channel ECG signals were simultaneously recorded from subjects with age from 18 to 35. For each subject, the PPG signals were recorded from wrist by two pulse oximeters with green LEDs (wavelength: 515nm). Their distance (from center to center) was 2 cm. The acceleration signal was also recorded from wrist by a three-axis accelerometer. Both the pulse oximeter and the accelerometer were embedded in a wristband, which was comfortably worn. The ECG signal was recorded simultaneously from the chest using wet ECG sensors. All signals were sampled at 125 Hz and sent to a nearby computer via Bluetooth.\n",
    "Link to the dataset - https://zenodo.org/record/3902710"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T10:34:48.354623Z",
     "start_time": "2023-08-28T10:34:39.594404Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from fedot_ind.api.utils.path_lib import PROJECT_PATH\n",
    "from fedot.core.pipelines.pipeline_builder import PipelineBuilder\n",
    "from fedot_ind.core.architecture.preprocessing.DatasetLoader import DataLoader\n",
    "from fedot_ind.core.repository.initializer_industrial_models import IndustrialModels\n",
    "from examples.example_utils import init_input_data, calculate_regression_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The list of basic fedot industrial models for experiment are shown below. We using simple linear machine learning pipelines with 3 different feature generators: Statistical, Reccurence, Topological. And for each of them we add PCA transformation with 90 % of explained dispersion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    'regression_with_statistical_features': PipelineBuilder().add_node('quantile_extractor',\n",
    "                                                                       params={'window_size': 10}).add_node('ridge'),\n",
    "    'regression_pca_with_statistical_features': PipelineBuilder().add_node('quantile_extractor',\n",
    "                                                                           params={'window_size': 10}).\n",
    "    add_node('pca', params={'n_components': 0.9}).add_node('ridge'),\n",
    "    'regression_with_reccurence_features': PipelineBuilder().add_node('recurrence_extractor',\n",
    "                                                                           params={'window_size': 20}).add_node('ridge'),\n",
    "    'regression_pca_with_reccurence_features': PipelineBuilder().add_node('recurrence_extractor',\n",
    "                                                                           params={'window_size': 20}).\n",
    "    add_node('pca', params={'n_components': 0.9}).add_node('ridge'),\n",
    "    'regression_with_topological_features': PipelineBuilder().add_node('topological_extractor',\n",
    "                                                                           params={'window_size': 20}).\n",
    "    add_node('pca', params={'n_components': 0.9}).add_node('ridge'),\n",
    "    'regression_pca_with_topological_features': PipelineBuilder().add_node('topological_extractor',\n",
    "                                                                           params={'window_size': 20}).\n",
    "    add_node('pca', params={'n_components': 0.9}).add_node('ridge')\n",
    "}\n",
    "metric_dict = {}\n",
    "dataset_name = 'IEEEPPG'\n",
    "data_path = PROJECT_PATH + '/examples/data'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we must download the dataset. It could be done by using `DataReader` class that implemented as attribute of `FedotIndustrial` class. This class firstly tries to read the data from local project folder `data_path` and then if it is not possible, it downloads the data from the UCR/UEA archive. The data will be saved in the `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T10:35:13.321212Z",
     "start_time": "2023-08-28T10:35:12.913025Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-09 15:31:22,666 - Reading data from D:\\WORK\\Repo\\Industiral\\IndustrialTS/examples/data/IEEEPPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "inconsistent number of dimensions. Expecting 5 but have read 0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "File \u001B[1;32mD:\\WORK\\Repo\\Industiral\\IndustrialTS\\fedot_ind\\core\\architecture\\preprocessing\\DatasetLoader.py:705\u001B[0m, in \u001B[0;36mDataLoader.read_ts_files\u001B[1;34m(self, dataset_name, data_path)\u001B[0m\n\u001B[0;32m    704\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 705\u001B[0m     x_test, y_test \u001B[38;5;241m=\u001B[39m \u001B[43mload_from_tsfile_to_dataframe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_path\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mdataset_name\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m_TEST.ts\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    706\u001B[0m \u001B[43m                                                   \u001B[49m\u001B[43mreturn_separate_X_and_y\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    707\u001B[0m     x_train, y_train \u001B[38;5;241m=\u001B[39m load_from_tsfile_to_dataframe(\n\u001B[0;32m    708\u001B[0m         data_path \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m dataset_name \u001B[38;5;241m+\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdataset_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_TRAIN.ts\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    709\u001B[0m         return_separate_X_and_y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32mD:\\WORK\\Repo\\Industiral\\venv_3.9\\lib\\site-packages\\sktime\\datasets\\_data_io.py:996\u001B[0m, in \u001B[0;36mload_from_tsfile_to_dataframe\u001B[1;34m(full_file_path_and_name, return_separate_X_and_y, replace_missing_vals_with)\u001B[0m\n\u001B[0;32m    995\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m this_line_num_dim \u001B[38;5;241m!=\u001B[39m num_dimensions:\n\u001B[1;32m--> 996\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\n\u001B[0;32m    997\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minconsistent number of dimensions. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    998\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpecting \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    999\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(num_dimensions)\n\u001B[0;32m   1000\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m but have read \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1001\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(this_line_num_dim)\n\u001B[0;32m   1002\u001B[0m     )\n\u001B[0;32m   1003\u001B[0m \u001B[38;5;66;03m# Process the data for each dimension\u001B[39;00m\n",
      "\u001B[1;31mOSError\u001B[0m: inconsistent number of dimensions. Expecting 5 but have read 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mException\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m _, train_data, test_data \u001B[38;5;241m=\u001B[39m \u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataset_name\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_train_test_files\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdata_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\WORK\\Repo\\Industiral\\IndustrialTS\\fedot_ind\\core\\architecture\\preprocessing\\DatasetLoader.py:93\u001B[0m, in \u001B[0;36mDataLoader.read_train_test_files\u001B[1;34m(self, data_path, dataset_name)\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misfile(file_path \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.ts\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m     92\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mReading data from \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdata_path\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39mdataset_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 93\u001B[0m     x_train, y_train, x_test, y_test \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_ts_files\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     94\u001B[0m     is_multi \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;66;03m# If data unpacked as .arff file\u001B[39;00m\n",
      "File \u001B[1;32mD:\\WORK\\Repo\\Industiral\\IndustrialTS\\fedot_ind\\core\\architecture\\preprocessing\\DatasetLoader.py:712\u001B[0m, in \u001B[0;36mDataLoader.read_ts_files\u001B[1;34m(self, dataset_name, data_path)\u001B[0m\n\u001B[0;32m    710\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x_train, y_train, x_test, y_test\n\u001B[0;32m    711\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m--> 712\u001B[0m     x_test, y_test \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_from_tsfile_to_dataframe\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    713\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata_path\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mdataset_name\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m_TEST.ts\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    714\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_separate_X_and_y\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    715\u001B[0m     x_train, y_train \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_load_from_tsfile_to_dataframe(\n\u001B[0;32m    716\u001B[0m         data_path \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m dataset_name \u001B[38;5;241m+\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdataset_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_TRAIN.ts\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    717\u001B[0m         return_separate_X_and_y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    718\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x_train, y_train, x_test, y_test\n",
      "File \u001B[1;32mD:\\WORK\\Repo\\Industiral\\IndustrialTS\\fedot_ind\\core\\architecture\\preprocessing\\DatasetLoader.py:600\u001B[0m, in \u001B[0;36mDataLoader._load_from_tsfile_to_dataframe\u001B[1;34m(self, full_file_path_and_name, return_separate_X_and_y, replace_missing_vals_with)\u001B[0m\n\u001B[0;32m    598\u001B[0m \u001B[38;5;66;03m# All dimensions should be included for all series, even if they are empty\u001B[39;00m\n\u001B[0;32m    599\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m this_line_num_dimensions \u001B[38;5;241m!=\u001B[39m num_dimensions:\n\u001B[1;32m--> 600\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m TsFileParseException(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minconsistent number of dimensions. Expecting \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(\n\u001B[0;32m    601\u001B[0m         num_dimensions) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m but have read \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(this_line_num_dimensions))\n\u001B[0;32m    603\u001B[0m \u001B[38;5;66;03m# Process the data for each dimension\u001B[39;00m\n\u001B[0;32m    604\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dim \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, num_dimensions):\n",
      "\u001B[1;31mException\u001B[0m: inconsistent number of dimensions. Expecting 5 but have read 0"
     ]
    }
   ],
   "source": [
    "_, train_data, test_data = DataLoader(dataset_name=dataset_name).read_train_test_files(\n",
    "            dataset_name=dataset_name,\n",
    "            data_path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_data = init_input_data(train_data[0], train_data[1], task='regression')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lets check our data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_data.features.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lets visualise our predictors."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "pd.DataFrame(input_data.features[1, 0, :]).plot(title='1 channel PPG signal')\n",
    "pd.DataFrame(input_data.features[1, 1, :]).plot(title='2 channel PPG signal')\n",
    "pd.DataFrame(input_data.features[1, 2, :]).plot(title='x-axis acceleration')\n",
    "pd.DataFrame(input_data.features[1, 3, :]).plot(title='y-axis acceleration')\n",
    "pd.DataFrame(input_data.features[1, 4, :]).plot(title='z-axis acceleration')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next steps are quite straightforward. We need to fit the model and then predict the values for the test data just like for any other model in sklearn.\n",
    "\n",
    "At the `fit` stage FedotIndustrial will transform initial time series data into features dataframe and will train regression model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-28T10:35:27.965798Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m input_data \u001B[38;5;241m=\u001B[39m init_input_data(\u001B[43mtrain_data\u001B[49m[\u001B[38;5;241m0\u001B[39m], train_data[\u001B[38;5;241m1\u001B[39m], task\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mregression\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      2\u001B[0m val_data \u001B[38;5;241m=\u001B[39m init_input_data(test_data[\u001B[38;5;241m0\u001B[39m], test_data[\u001B[38;5;241m1\u001B[39m], task\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mregression\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m IndustrialModels():\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "input_data = init_input_data(train_data[0], train_data[1], task='regression')\n",
    "val_data = init_input_data(test_data[0], test_data[1], task='regression')\n",
    "with IndustrialModels():\n",
    "    for model in model_dict.keys():\n",
    "        print(f'Current_model - {model}')\n",
    "        pipeline = model_dict[model].build()\n",
    "        pipeline.fit(input_data)\n",
    "        features = pipeline.predict(val_data).predict\n",
    "        metric = calculate_regression_metric(test_target=test_data[1], labels=features)\n",
    "        metric_dict.update({model: metric})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "At the end of the experiment we can obtain the desired metric values using `calculate_regression_metric` method. Now there are five available metrics for classification task:\n",
    "- `explained_variance_score`\n",
    "- `max_error`\n",
    "- `mean_absolute_error`\n",
    "- `mean_squared_error`\n",
    "- `d2_absolute_error_score`.\n",
    "- `median_absolute_error`\n",
    "- `r2_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T11:01:34.941934Z",
     "start_time": "2023-08-28T11:01:34.928460Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(metric_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}